"""
ë©”ì¸ ì• í”Œë¦¬ì¼€ì´ì…˜
"""
import argparse
import sys
from typing import Optional

from config_manager import ConfigManager
from llm_provider import LLMProviderManager, LLMConnectionError
from prompt_optimizer import PromptOptimizer, OptimizationError
from workflow import PromptOptimizationWorkflow
from display import DisplayManager


class PromptOptimizerApp:
    """í”„ë¡¬í”„íŠ¸ ìµœì í™” ì• í”Œë¦¬ì¼€ì´ì…˜"""
    
    def __init__(self, config_path: Optional[str] = None):
        """
        Args:
            config_path: ì„¤ì • íŒŒì¼ ê²½ë¡œ
        """
        # ì„¤ì • ë¡œë“œ
        self.config_manager = ConfigManager(config_path)
        llm_config = self.config_manager.get_llm_config()
        display_config = self.config_manager.get_display_config()
        
        # ë””ìŠ¤í”Œë ˆì´ ë§¤ë‹ˆì € ì´ˆê¸°í™”
        self.display = DisplayManager(
            show_timestamps=display_config.show_timestamps,
            color_output=display_config.color_output
        )
        
        # í—¤ë” í‘œì‹œ
        self.display.show_header()
        
        try:
            # LLM Provider ì´ˆê¸°í™”
            self.display.show_info("LLM ì„œë¹„ìŠ¤ ì—°ê²° ì¤‘...")
            self.llm_provider = LLMProviderManager(
                provider=llm_config.provider,
                model=llm_config.model,
                base_url=llm_config.base_url,
                temperature=llm_config.temperature,
                max_tokens=llm_config.max_tokens
            )
            self.display.show_success("LLM ì„œë¹„ìŠ¤ ì—°ê²° ì„±ê³µ!")
            self.display.show_provider_info(self.llm_provider.get_provider_info())
            
        except LLMConnectionError as e:
            self.display.show_error(e, "LLM ì´ˆê¸°í™”")
            self._show_connection_help(llm_config.provider)
            sys.exit(1)
        
        # Prompt Optimizer ì´ˆê¸°í™”
        self.prompt_optimizer = PromptOptimizer(self.llm_provider)
        
        # Workflow ì´ˆê¸°í™”
        self.workflow = PromptOptimizationWorkflow(
            self.llm_provider,
            self.prompt_optimizer,
            self.display
        )
    
    def _show_connection_help(self, provider: str):
        """
        ì—°ê²° ë„ì›€ë§ í‘œì‹œ
        
        Args:
            provider: LLM ì œê³µì
        """
        if provider == 'ollama':
            print("\nğŸ’¡ Ollama ì—°ê²° ë¬¸ì œ í•´ê²°:")
            print("   1. Ollamaê°€ ì„¤ì¹˜ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸: https://ollama.ai")
            print("   2. Ollama ì„œë¹„ìŠ¤ ì‹¤í–‰: ollama serve")
            print("   3. ëª¨ë¸ ë‹¤ìš´ë¡œë“œ: ollama pull llama2")
            print("   4. í¬íŠ¸ í™•ì¸: ê¸°ë³¸ í¬íŠ¸ëŠ” 11434")
        
        elif provider == 'lmstudio':
            print("\nğŸ’¡ LM Studio ì—°ê²° ë¬¸ì œ í•´ê²°:")
            print("   1. LM Studioê°€ ì„¤ì¹˜ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸: https://lmstudio.ai")
            print("   2. LM Studio ì‹¤í–‰ í›„ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ")
            print("   3. 'Local Server' íƒ­ì—ì„œ ì„œë²„ ì‹œì‘")
            print("   4. í¬íŠ¸ í™•ì¸: ê¸°ë³¸ í¬íŠ¸ëŠ” 1234")
    
    def run(self, query: str) -> dict:
        """
        ì§ˆì˜ ì‹¤í–‰
        
        Args:
            query: ì‚¬ìš©ì ì§ˆì˜
            
        Returns:
            ì‹¤í–‰ ê²°ê³¼
        """
        try:
            # ì›Œí¬í”Œë¡œìš° ì‹¤í–‰
            final_state = self.workflow.run(query)
            
            # ìš”ì•½ í‘œì‹œ
            self.display.show_summary()
            
            # ì˜¤ë¥˜ í™•ì¸
            if final_state.get('error'):
                self.display.show_error(
                    Exception(final_state['error']),
                    "ì›Œí¬í”Œë¡œìš° ì‹¤í–‰"
                )
                return {'success': False, 'error': final_state['error']}
            
            self.display.show_success("í”„ë¡¬í”„íŠ¸ ìµœì í™” ì™„ë£Œ!")
            
            return {
                'success': True,
                'original_query': final_state['original_query'],
                'optimized_prompt': final_state['optimized_prompt'],
                'llm_response': final_state['llm_response'],
                'analysis': final_state['analysis'],
                'timestamps': final_state['timestamps']
            }
            
        except OptimizationError as e:
            self.display.show_error(e, "ìµœì í™”")
            return {'success': False, 'error': str(e)}
        
        except Exception as e:
            self.display.show_error(e, "ì‹¤í–‰")
            return {'success': False, 'error': str(e)}
    
    def run_interactive(self):
        """ëŒ€í™”í˜• ëª¨ë“œ ì‹¤í–‰"""
        self.display.show_info("ëŒ€í™”í˜• ëª¨ë“œ ì‹œì‘ (ì¢…ë£Œ: 'quit' ë˜ëŠ” 'exit')")
        
        while True:
            try:
                # ì‚¬ìš©ì ì…ë ¥
                print(f"\n{'-'*60}")
                query = input("ì§ˆì˜ë¥¼ ì…ë ¥í•˜ì„¸ìš”: ").strip()
                
                # ì¢…ë£Œ í™•ì¸
                if query.lower() in ['quit', 'exit', 'ì¢…ë£Œ']:
                    self.display.show_info("í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
                    break
                
                # ë¹ˆ ì…ë ¥ í™•ì¸
                if not query:
                    self.display.show_warning("ì§ˆì˜ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
                    continue
                
                # ì§ˆì˜ ì‹¤í–‰
                self.run(query)
                
            except KeyboardInterrupt:
                print("\n")
                self.display.show_info("í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
                break
            
            except Exception as e:
                self.display.show_error(e, "ëŒ€í™”í˜• ëª¨ë“œ")


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    parser = argparse.ArgumentParser(
        description='LangChain Prompt Optimizer - í”„ë¡¬í”„íŠ¸ ìµœì í™” ì‹œìŠ¤í…œ'
    )
    
    parser.add_argument(
        '--config',
        type=str,
        default='config/ollama_config.yaml',
        help='ì„¤ì • íŒŒì¼ ê²½ë¡œ (ê¸°ë³¸: config/ollama_config.yaml)'
    )
    
    parser.add_argument(
        '--query',
        type=str,
        help='ì‹¤í–‰í•  ì§ˆì˜'
    )
    
    parser.add_argument(
        '--interactive',
        action='store_true',
        help='ëŒ€í™”í˜• ëª¨ë“œ ì‹¤í–‰'
    )
    
    args = parser.parse_args()
    
    try:
        # ì•± ì´ˆê¸°í™”
        app = PromptOptimizerApp(config_path=args.config)
        
        # ì‹¤í–‰ ëª¨ë“œ ê²°ì •
        if args.interactive:
            # ëŒ€í™”í˜• ëª¨ë“œ
            app.run_interactive()
        
        elif args.query:
            # ë‹¨ì¼ ì§ˆì˜ ëª¨ë“œ
            app.run(args.query)
        
        else:
            # ì¸ìê°€ ì—†ìœ¼ë©´ ë„ì›€ë§ í‘œì‹œ
            parser.print_help()
            print("\nì˜ˆì œ:")
            print("  python src/main.py --query 'íŒŒì´ì¬ìœ¼ë¡œ ì›¹ ìŠ¤í¬ë˜í•‘í•˜ëŠ” ë°©ë²•'")
            print("  python src/main.py --interactive")
            print("  python src/main.py --config config/lmstudio_config.yaml --query 'ë¨¸ì‹ ëŸ¬ë‹ ê¸°ì´ˆ'")
    
    except Exception as e:
        print(f"\nâŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        sys.exit(1)


if __name__ == '__main__':
    main()
